
# Cron Metrics Collector & Exporter (Go Edition)

### Database Layer

**All database access must use [sqlx](https://github.com/jmoiron/sqlx).**

- All queries must be parameterized (no string interpolation)
- All DB helpers and stores use `*sqlx.DB`
- See `pkg/model/database.go` for canonical usage

#### Migration Note
Legacy code using `database/sql` has been fully migrated to `sqlx` as of November 2025. All contributors must follow this pattern.

## Overview

A Go-based API and web server to centralize cron job results and export their statuses as Prometheus-compatible metrics. Focused on simple curl integration, fast and robust deployment, complete lifecycle management (CRUD API), and sophisticated monitoring‚Äîincluding maintenance/alert suppression and structured, maintainable code and docs.

## Key Features

- Central REST API for job result submissions (/api/job-result/) and full CRUD management of jobs
- Prometheus /metrics endpoint displaying per-job status, totals, and label-rich job metrics
- Per-job automatic failure threshold (auto-marks jobs as failed if silence exceeds threshold)
- Arbitrary user-defined labels per job for flexible Prometheus queries and UI filtering
- Maintenance mode: jobs can be paused to suppress alerting/downtime without removal
- Admin CLI for all job management operations
- Strictly versioned configuration and code, reproducible builds, and up-to-date docs

## Functional Requirements

- Job Management:
  - CRUD operations for job definitions via API and CLI:
    - Create: Register new job (name, host, threshold, labels, status)
    - Read: List/filter all jobs
    - Update: Modify thresholds, labels, maintenance flag
    - Delete: Remove job definition
  - Job status/lifecycle flags (active, maintenance, paused, retired), adjustable at runtime via API/CLI
  - Maintenance/paused jobs are excluded from alerting in /metrics, and clearly flagged in all outputs
- Metrics and Monitoring:
  - /metrics endpoint outputs Prometheus-formatted metrics:
    - Per-job status (cronjob_status), last run, last error, auto-failure reason/expiry, all labels
    - Jobs in maintenance/status have value -1 or a dedicated status="maintenance" label
  - Automatic failure if no result within automatic_failure_threshold (per job)
  - Metrics include all user-supplied labels
- Security:
  - Two-tier authentication system for enhanced security isolation
  - Admin API keys for job management operations (CRUD endpoints)
  - Per-job API keys for result submissions (unique key per job)
  - Automatic API key generation with secure random data and validation
  - Job isolation: each job can only submit results for itself
  - All endpoints over HTTPS in production
- Data Retention:
  - Configurable retention above default (e.g., 30 or 90 days)
  - Option to purge logs, redact sensitive ‚Äúoutput‚Äù fields
- Admin Tooling & Dashboard:
  - Cobra CLI commands for serve, job CRUD, config management
  - Simple API-driven UI/dashboard for browsing/filtering jobs and statuses (optional in MVP)

## Non-Functional Requirements

- Containerized build (Docker), static Linux binary, comprehensive GitHub Actions CI/CD pipeline
- <300 ms /metrics for up to 10,000 jobs
- Pure Go codebase, Viper config (YAML + env overrides), structured logging (Zap or Logrus)
- Documentation always up-to-date as source of project truth

## API/Job Structure

### Job Definition Example

```json
{
  "id": 42,
  "job_name": "db_import",
  "host": "backup3",
  "api_key": "cm_abcd1234567890abcdef123456789abcdef123456789abcd",
  "automatic_failure_threshold": 3600,
  "labels": {
    "env": "stage",
    "team": "migration"
  },
  "status": "maintenance"
}
```

### JobResult Submission Example

```bash
# Using job-specific API key for result submission
curl -X POST http://localhost:8080/api/job-result \
  -H "Content-Type: application/json" \
  -H "X-API-Key: cm_abc123456789abcdef123456789abcdef123456789abcd" \
  -d '{
    "job_name": "sync_db",
    "host": "web1",
    "status": "success",
    "labels": {
      "env": "prod",
      "team": "infra",
      "type": "backup"
    },
    "duration": 27,
    "timestamp": "2025-10-30T19:56:00Z"
  }'
```

**Security Note**: Each job can only submit results for itself. The API validates that the job name and host in the request match the job associated with the provided API key.

### Prometheus Metrics Example

```text
# HELP cronjob_status Status of cron job: 1=success, 0=failure, -1=maintenance/paused
# TYPE cronjob_status gauge

# Active job with successful result
cronjob_status{job_name="sync_db",host="web1",env="prod",team="infra",status="success"} 1

# Active job with failed result
cronjob_status{job_name="backup",host="web2",env="prod",status="failure"} 0

# Job that missed its deadline (auto-failed)
cronjob_status{job_name="cleanup",host="web3",env="prod",status="missed_deadline"} 0

# Maintenance mode job (no alerting)
cronjob_status{job_name="db_import",host="backup3",env="stage",status="maintenance"} -1

# HELP cronjob_last_run_timestamp Timestamp of last job execution
# TYPE cronjob_last_run_timestamp gauge
cronjob_last_run_timestamp{job_name="sync_db",host="web1"} 1698758400

# HELP cronjob_total Total number of registered cron jobs
# TYPE cronjob_total gauge
cronjob_total 4
```

**Key Metrics Features:**

- **Status Labels**: All metrics include `status` labels for precise alerting
- **User Labels**: Custom job labels are automatically included in metrics
- **Automatic Failure Detection**: Jobs exceeding thresholds get `status="missed_deadline"`
- **Maintenance Support**: Maintenance jobs get `status="maintenance"` and value `-1` for alert suppression

### Authentication System

The system implements a two-tier authentication model:

#### Admin API Keys

- **Purpose**: Job management operations (CRUD)
- **Configuration**: `CRONMETRICS_SECURITY_ADMIN_API_KEYS` environment variable
- **Usage**: Required for all job management endpoints
- **Header**: `Authorization: Bearer <admin-api-key>`

#### Per-Job API Keys

- **Purpose**: Job result submissions (isolated per job)
- **Generation**: Automatically generated when creating jobs (or custom via `--api-key`)
- **Format**: `cm_` prefix + base32-encoded random data (52 chars)
- **Usage**: Each job uses its own unique key for result submissions
- **Header**: `X-API-Key: <job-specific-api-key>`
- **Security**: Jobs can only submit results for themselves

### OpenAPI (Swagger) API

Complete API documentation is available through multiple formats:

- **Interactive Documentation**: Swagger UI at `/swagger/` endpoint
- **Machine-readable Spec**: OpenAPI 3.0.3 specification at `/api/openapi.yaml`
- **Source Documentation**: `docs/openapi.yaml` contains the complete schema

#### API Endpoints

- `/api/job` [POST, GET] ‚Äî create/list jobs (Admin API key required)
- `/api/job/{id}` [GET, PUT, DELETE] ‚Äî read/update/delete single job (Admin API key required)
- `/api/job-result` [POST] ‚Äî submit job result (Per-job API key required)
- `/metrics` [GET] ‚Äî Prometheus metrics (No authentication)
- `/health` [GET] ‚Äî Health check (No authentication)
- `/swagger/` [GET] ‚Äî Interactive Swagger UI documentation (No authentication)
- `/api/openapi.yaml` [GET] ‚Äî OpenAPI 3.1 specification (No authentication)

#### Swagger UI Features

The integrated Swagger UI provides:
- **Interactive API Testing**: Execute API calls directly from the browser
- **Authentication Support**: Built-in support for both admin and per-job API key authentication
- **Schema Documentation**: Complete request/response schemas with examples
- **Real-time Validation**: Input validation and error handling examples
- **Export Capabilities**: Download OpenAPI spec for external tooling

### Web Dashboard (Optional Feature)

#### Overview

The web dashboard provides a visual interface for job monitoring and management, built using Gin framework with HTMX for real-time updates.

**Route:** `GET /dashboard`
**Purpose:** Provide a simple HTML interface for job monitoring

#### Visual Deadline Status Indicators

The dashboard displays clear visual indicators for job health based on automatic failure thresholds:

- **üü¢ Green (Success)**: Job reported within deadline (on time)
- **üü° Yellow (Warning)**: Job approaching deadline (80% of threshold reached)
- **üî¥ Red (Danger)**: Job missed deadline (past AutomaticFailureThreshold)
- **‚ö´ Gray (Inactive)**: Job in maintenance or paused status

**Status Calculation Logic:**
```go
// Same logic as Prometheus metrics system
now := time.Now().UTC()
timeSinceLastReport := now.Sub(job.LastReportedAt)
thresholdDuration := time.Duration(job.AutomaticFailureThreshold) * time.Second

if timeSinceLastReport > thresholdDuration {
    return "danger"  // Missed deadline
}

warningThreshold := time.Duration(float64(job.AutomaticFailureThreshold) * 0.8) * time.Second
if timeSinceLastReport > warningThreshold {
    return "warning"  // Approaching deadline
}

return "success"  // On time
```

#### Features

- **Job overview table** with real-time status monitoring
- **Search and filtering** by job name, host, or labels
- **Job management** - create, edit, toggle maintenance mode
- **Real-time updates** via Server-Sent Events or polling fallback
- **Responsive design** that works on desktop and mobile
- **Visual deadline tracking** based on per-job thresholds
- **Authentication** with admin API keys

#### Configuration

```yaml
dashboard:
  enabled: true                # Enable/disable dashboard
  path: "/dashboard"          # Dashboard URL path
  title: "Cron Metrics"      # Dashboard title
  auth_required: true         # Require admin API key
  refresh_interval: 30        # Auto-refresh interval (seconds)
  page_size: 25              # Jobs per page
  # Real-time updates
  sse_enabled: true           # Server-Sent Events
  sse_timeout: 30            # SSE connection timeout
  sse_heartbeat: 10          # SSE heartbeat interval
  sse_max_clients: 100       # Max concurrent SSE clients
  polling_fallback: true     # HTMX polling fallback
  polling_interval: 5        # Polling interval (seconds)
```

### Tooling & Codebase

- Cobra: CLI structure (cmd/cronmetrics for serve, job, config, etc.)
- Viper: Unified config loader (YAML + env), reloadable at runtime
- Logrus/Zap: Structured logging
- mise: Build/test/env standardization, managed with .tool-versions
- Project Layout:

```text
/cmd/cronmetrics
/pkg/api
/pkg/metrics
/pkg/config
/pkg/model
/pkg/log
/internal/cli
/docs/
.tool-versions
.env
```

### CLI Example

```bash
# Server management
cronmetrics serve --config /etc/cronmetrics/config.yaml

# Job management with API key generation
cronmetrics job add --name backup --host db1 --threshold 600 --label env=prod
# Output: Job ID 1 ('backup@db1') created successfully
#         API Key: cm_abc123456789abcdef123456789abcdef123456789abcd
#         NOTE: Save this API key for your cron jobs to submit results.
#         You can retrieve it later using: cronmetrics job show 1

# Job management with custom API key
cronmetrics job add --name backup2 --host db1 --api-key cm_custom-key --threshold 600

# Update job settings (using job ID)
cronmetrics job update 1 --maintenance
cronmetrics job update 1 --api-key cm_new-rotated-key
cronmetrics job update 2 --name backup2-renamed --host db2  # Can update name/host via ID

# List jobs with API key visibility
cronmetrics job list --label env=prod
cronmetrics job list --show-api-keys  # Shows masked keys for security
cronmetrics job show 1  # Shows full API key and job details
```

### Logging Conventions

- Structured logging (Zap or Logrus), key-value pairs
- Context: Always log job, host, user, request_id, and error/return where relevant
- Log Levels:
  - DEBUG: Function entry/exit with params/returns (when enabled)
  - INFO: System lifecycle, submission/crud events
  - WARNING: Recoverable issues (invalid config, submission rejections)
  - ERROR: Critical errors, panics, data loss risks
- Log in UTC, RFC3339 timestamps, always thread safe

### Documentation & Maintainability

- `/docs/` directory contains API spec (OpenAPI), admin/usage/config guides, changelog
- All PRs and code changes must update docs
- Linting and doc-completeness checks in CI
- README, CONTRIBUTING, and onboarding step-by-step for devs

### Testing & Quality Assurance

#### Comprehensive Test Suite (100% Passing) ‚úÖ

- **Unit Tests**: Core business logic validation
- **Integration Tests**: Full API and CLI coverage with real database
- **End-to-End Tests**: Complete workflow scenarios
- **Test Coverage**: All endpoints, authentication flows, metrics validation
- **Quality Gates**: All tests must pass before deployment

**Test Categories:**

- API endpoint validation (CRUD operations, authentication, error handling)
- CLI command testing (all subcommands and flags)
- Prometheus metrics format verification
- Database migrations and data integrity
- Authentication system (admin keys, per-job keys, isolation)

### Acceptance Criteria

- ‚úÖ CRUD lifecycle for jobs (API + CLI), maintenance flag functioning as required
- ‚úÖ Prometheus metrics correctly represent all job/label/status cases with proper status labels
- ‚úÖ Two-tier authentication system with per-job isolation working correctly
- ‚úÖ Logging, configuration, and documentation all adhere to established conventions
- ‚úÖ Complete test suite with 100% pass rate providing confidence in system reliability
- ‚úÖ MVP release includes end-to-end example, CI pipeline, and up-to-date docs

### CI/CD and Automation ‚úÖ

**GitHub Actions Pipeline:**
- **Automated Testing**: Full test suite on every push and pull request
- **Security Scanning**: Gosec, govulncheck, and Trivy container scanning
- **Multi-platform Builds**: Automatic binary builds for Linux, macOS, Windows
- **Container Publishing**: Multi-architecture Docker images to GitHub Container Registry
- **Release Automation**: Tag-triggered releases with changelog generation
- **Dependency Management**: Automated weekly updates via Dependabot

**Container Support:**
- Multi-stage Docker builds with security best practices
- Multi-architecture support (linux/amd64, linux/arm64)
- Docker Compose setup with Prometheus and Grafana
- Published to `ghcr.io/jaepetto/cron-exporter`

**Quality Assurance:**
- Code coverage reporting via Codecov
- Comprehensive linting and formatting checks
- All builds and tests must pass before merge
- Automated security vulnerability scanning

### Changelog

- v0.4, 2025-10-31: **Complete CI/CD Pipeline and Containerization**
  - GitHub Actions workflows for automated testing, building, and releasing
  - Multi-platform Docker images with security scanning
  - Automated release pipeline with tag-triggered builds
  - Docker Compose setup with monitoring stack (Prometheus, Grafana)
  - Dependabot configuration for automated dependency updates
  - Code coverage integration with Codecov
  - Comprehensive documentation updates for CI/CD workflow

- v0.3, 2025-10-31: **Production-Ready Release with Full Test Coverage**
  - Enhanced Prometheus metrics with proper status labels (`status="success"`, `status="failure"`, `status="maintenance"`)
  - Improved metrics collector to determine actual job status from job results instead of heuristics
  - Fixed API status codes - job result submissions now correctly return HTTP 201 (Created)
  - Comprehensive test suite achieving 100% pass rate (integration + end-to-end)
  - Removed flaky concurrent tests focusing on SQLite edge cases
  - Enhanced CLI error handling and user feedback
  - Updated documentation to reflect all current features and capabilities

- v0.2, 2025-10-31: **Per-job API key authentication system**
  - Added two-tier authentication (admin keys vs per-job keys)
  - Implemented automatic API key generation with `cm_` prefix
  - Enhanced security with job-specific result submission validation
  - Updated CLI with API key management features
  - Added database migration for API key storage

- v0.1, 2025-10-30: Initial specification and system design
